---
title: "苏证通面试题"
date: 2024-10-12
description: ""
cover: https://github.com/Gjt-9520/MarkDownBlog/blob/main/source/coverImages/Aimage-135/Aimage23.jpg?raw=true
tags: ["JavaEE"]
category: "面试"
updated: 2024-10-13
  
top_group_index: 
---

# 自我介绍

面试官，你好，我叫顾锦涛，本科毕业于常州大学，专业是计算机科学与技术。我目前的技术栈主要包括SpringBoot、SpringCloud、MySQL、Redis、MyBatis、RabbitMQ、RocketMQ、xxl-Job等。

我是一个热爱技术并且坚持学习的人，平时学习的平台有B站、CSDN等。此外，我还会经常在技术博客、GitHub、StackOverflow上学习其他优秀开发者的技术并分享经验。

我从事Java开发有1年时间了，之前在南京汇龙科技有限公司做Java后端开发，我所在的部门是智慧城市部门，主要负责政府方面的办证办件业务。

我最近参与的一个项目是苏证通APP的开发，这个应用主要是方便用户的线上证件办理，例如身份证、营业执照、建筑师证等。没有这个平台之前，用户需要携带材料去线下申请，完成不同环节的资料审核，浪费很多时间；而通过我们的平台，用户可以线上申请、办理、审核。

我们平台将用户填写的材料信息，通过接口传到需要审核的地市，地市审核通过后将审核信息回传给应用，用户就可以在苏证通的详情页面查看流程，如果证件办好，用户只需要填写收货地址就可以通过邮寄拿到证件，如果材料缺失，用户可以直接在平台上补齐补正即可，这极大程度上便利了用户，节省了用户时间，提高了办证效率。

# 负责日常需求的开发，联调，上线（例如：开发其他申请单业务，开发审批超时提醒功能，后台管理系统数据的增删改查等）。

## 开发其他申请单业务：

我和我的导师会出差，和第三方对接。主要调研能不能做，办证需要哪些要求，第三方能够提供哪些数据、哪些接口给我们。

如果对接没有问题，我就负责开发这些需求。

前端页面会把用户填写的信息传到服务器接口，我们会先进行参数校验，字段是否为空、字段是否满足要求等。可能有些数据，前端只有用户id，但是第三方需要详细的用户信息，就需要我们查出用户信息，插入数据库或者es，记录表进行记录，把数据整合封装好再调用第三方的接口传给第三方，获取返回结果再写入数据库。

### 传给第三方的数据有哪些：

用户的身份证号、姓名、手机号、材料图片、用户地址（省/区/县）、

json字符串（根据不同的申报类型会有不同的数据，例如查高考成绩这里就是准考证号、科目名称；如果是营业执照就需要传店铺的一些信息，比如店铺类型、店铺地点、统一社会编码等）

### 接口调用了第三方，如何保证事务问题？

我们事务提交的方式改成手动提交，并且第三方的调用接口一般会放在方法的最后一行，这样就能通过第三方接口的返回成功/失败来选择全局提交/回滚。

这个仅限于第三方接口的返回值对我们的业务没有影响，如果有影响的话，就只能通过分布式事务去处理，例如Seata。

```java

```

### 接口的安全性怎么保证？

第一种做法：最好使用https协议，因为它在http和tcp之间加了一层加密层（SSL层：负责数据的加密和解密，防止数据被抓包）。

第二种做法：在每次请求的消息体中加入当前时间，然后服务器拿到消息中的时间与当前时间相减，看这个是否是在一个固定的时间范围内的请求，例如5分钟，如果超时了，那就是非法请求，因为恶意请求是无法更改消息中的时间的。

第三种做法：使用md5算法，将需要提交的数据通过某种方式组合成一个字符串，然后通过md5生成一段加密字符串，客户端和服务端都计算一份，防止数据传输被篡改。

第四种做法：对接口的访问ip进行黑白名单配置。

### 第三方接口超时怎么办？

在发送http请求的时候，添加请求时间参数，设置的是5000ms，并且加重试机制，重试3次。

### 请求状态码？

200 成功

302 重定向

400 传参错误

401 权限不足

404 请求资源不存在

500 服务器错误

503 服务器当前不可用

## 开发审批超时提醒功能：

这个功能的背景是客服审批一些申请单的时间过长，用户长时间看不到审核结果，导致用户投诉。

然后，组长让我做一个申请单审批超时通知客服的功能，我首先想到的是用定时任务，定时扫描这些待审批的申请单，但是后面发现定时任务不太好控制时间，对于不同时间超时的申请单就需要启用多个定时任务，并且定时任务扫描还可能存在漏扫的情况。

后面考虑采用rocketmq的延时队列。用户创建申请单的时候，会将生成的申请单id和根据该申请单需要延时的类型（1小时/2小时/5小时/10分钟）发送给rocketmq的延时队列里面，然后到期后消费者那边会从消息体取出该申请单id，并通过数据库查询，数据库该申请单的状态，如果申请单状态还是待审核，发送邮件给对应的客服人员进行加急审核。

```java

```

### mq的消息积压怎么处理的？

这块增加消费者是最简单的方式，但是我们公司服务器固定了，所以我们是用多线程的方式进行消费，正常情况下多线程消费开关是关闭的，假如消息积压告警了，我们是在配置中心将开关打开，这样就采用多线程消费。

此外，在生产者这边，发送消息的消息体尽量占用较少的字节，尽可能在消费者那边进行数据查询和组装。

```java
// 配置中心监听器
public class ConfigListener {
    // 线程池（默认单线程）
    private static ExecutorService threadPool = Executors.newFixedThreadPool(1); 

    // 当配置中心开关变化时触发
    public static void switchThreadPool(boolean multiThreadMode) {
        if(multiThreadMode){
            // 紧急情况：开启20个线程的超级处理模式
            threadPool = Executors.newFixedThreadPool(20); 
            System.out.println("【爆单啦】启动20个骑手加速送餐！");
        } else {
            // 平时：保持1个线程的悠闲模式
            threadPool = Executors.newFixedThreadPool(1);
            System.out.println("恢复正常配送模式");
        }
    }
}

// 订单处理示例
public void processOrder(Message message) {
    threadPool.execute(() -> {
        System.out.println("处理订单：" + message.getId());
        // 实际的订单处理逻辑...
    });
}
```

### mq重复消费消息怎么解决的？
这一块，主要是通过redis中存消息id的中间状态来解决的。
我们会先把消息id存redis，消费之前，会先去redis中查看消息id是否存在，如果不存在则消费；如果存在，则查看状态是否是已完成，如果是未完成就直接抛异常，并且把redis中的消费id删除，需要mq重试；如果状态是已完成，则直接return不需要再消费；如果是正常消费成功，则把消息id的状态设置为已完成。
独立设计和开发库表交换需求，并对该需求中相关功能进行技术选型，同时对极端情况进行处理。
库表交换需求是什么？
之前我们公司主要是通过接口去对接第三方的，后面在对接一些公安部门的信息查询时，发现他们都是内网，对外不支持接口，但是能对外通过开放的服务器。后面经过需求讨论，设计了一套库表交换的需求，这个是由我来开发的。
大致的流程就是我们提供一个对外开放的服务器，把服务器的ip端口、数据库账号密码交给第三方。我们双方都通过定时任务，每隔1小时就去拉取对外服务器数据库里的数据，我们拉取审批数据，第三方拉取申报数据。
这个单从业务实现来说，并不难，但是在开发过程中需要考虑一些极端情况和异常情况。下面我说一下我在开发这个需求的时候，考虑的一些问题和技术方案的选型，主要是4个问题。
查询第三方数据库是以时间范围还是id为偏移量去查询？
最终采用的是以时间范围为偏移量去查询。比如定时任务1小时执行一次，就会查询执行前1小时的审批数据，假如这批数据有异常，并不会影响之后时间段的数据调度。而如果以id为偏移量去查询，假如这批数据有异常，任务就会循环重试，影响该批次之后的数据调度。
拉取第三方数据的时候，数据有问题导致代码异常，事务回滚怎么处理？
这个问题也是数据迁移都需要考虑的问题。首先，插入数据，我们加入了事务，如果异常了，这个时间段内的数据会进行回滚。然后，我们维护了一张重试表，表中字段有开始时间、结束时间，以及重试次数和状态，开启了一个定时任务，每5分钟执行一次，扫描该表待处理的异常任务，通过时间范围再去查询第三方数据插入我们的内部数据库。这样就把异常恢复和业务代码进行了分离，如果重试次数达到3次，就会邮件告警开发人员去人工处理。
之前我们内部数据库存储的用户敏感信息（如身份证号、手机号等）都是明文存储的，之后对接第三方时，第三方不允许传输明文，需要我们传加密后的用户敏感信息，而且第三方的对外数据库也是加密存储？
对于这种数据脱敏问题，一开始我们商讨，我们公司内部的数据库还是明文存储，但是放入对外数据库的数据进行加密，从第三方对外数据库中取数据时，也是先解密再插入我们的内部数据库。这种做法虽然在业务实现上简单，但是会导致内外数据库数据不一致，后续定位问题麻烦，后来组长开会决定，将公司内部的数据库中所有的用户敏感信息进行全量数据脱敏，采用aes对称加密，我们和第三方都存一份密钥。我们的数据先加密再入库，页面展示也是取出数据后，先解密再展示。
对用户的敏感信息进行全量数据脱敏也是比较麻烦的问题。增量数据处理起来比较简单，但是数据库中已有的存量数据也需要脱敏。表里的数据有400~500万，对于这个问题，最容易想到的就是查询一批数据，然后一条一条数据进行字段修改，然后再更改数据库。但是对于这么大的表，这种实现不合理，后面组长也说了，不能在原表上直接进行修改，这样修改会增加行锁，锁冲突的概率会非常高，影响用户体验。
之后，我自己上网调研了一些解决方案，最终采用一张新表来解决。原表的数据不做任何修改，写一个定时任务，通过月份查询一批数据，将该批数据的用户敏感信息进行字段修改，然后批量插入新表，一批1000条数据。为了尽可能避免用户新增数据，这个定时任务是晚上10点执行的，耗时将近1个小时，到晚上11点，所有的数据迁移完成，没有用户使用的时候，将旧表重命名，新表改为旧表名，然后第二天观察数据没有问题，再把旧表删除。
从第三方一批拉取的数据量太多，怎么保证插入数据的效率？
这个也是需要考虑的问题，主要是一个时间段内审批的数据量太多，比如10万，如果数据库是单条/批量插入数据也会有效率问题，如果不能及时更新数据到数据库，就会导致用户长时间查看不到审核结果。
为了解决这个问题，我首先想到的是多线程，但是多线程又有很多问题，比如多线程导入数据会导致事务失效，而且如果有一个线程异常了，其他线程无法感知。
我说一下我是怎么解决的：首先，自动提交事务改成手动提交事务，目的是防止多线程导致事务失效。然后，通过CountDownLatch来实现线程同步以及AtomicBoolean类型的布尔值来控制事务提交/回滚，让子线程等待其他子线程执行完成后，主线程再统一进行提交或回滚。如果有子线程异常，主线程就会通过布尔值感知到并触发回滚。此外，如果主线程等待子线程的时间超时，也会触发回滚。
对日常监控平台检测的慢sql进行调优，针对操作记录表数据较多问题通过水平拆分进行优化。
项目中优化过哪些慢sql？
定位过慢SQL，其中印象最深的就是隐式类型转换问题。之前，我们有一块业务很长时间都没动过，就是一张表里存了用户token，这个token是一串数字，当用户每次操作的时候，就会把这个token传给用户中心查询用户数据。
这个是之前业务开发好的，我主要是定位慢SQL。我说一下我定位这个问题的思路：先复现问题，确定具体的问题方法，再对方法进行深度排查，最后，通过不同的角度去验证该问题。
首先，我先模拟请求接口复现了这个问题，然后查看公司的链路追踪工具，发现耗时的方法就是通过token信息查询一些用户数据的方法。然后，我就进一步定位到这个方法里面的sql语句，sql语句其实很简单，就是通过这个token查询用户的一些信息，然后对字段进行了排序，但是这个简单的sql耗时有4~6秒，当时这个表的数据量在50万左右，也不是很大。
确定是sql问题之后，我就用explain去分析这条sql语句，发现type是all，extra出现了文件排序，当时我以为是没有符合最左前缀原则，后面发现这个sql的条件符合最左前缀原则。然后我就建立了一个索引去进行验证，发现只要加了token就是走全表扫描，没加token就是走索引。因为出现了索引失效，想到可能有几种情况：
1.没有符合最左前缀原则
2.联合索引中出现范围查询
3.存在隐式类型转换
4.like开头的模糊查询
5.or的连接条件中不全有索引
6.mysql评估走全表扫描更快
然后，我又查看了表的字段，发现和sql查询的数据类型不一样，这个token在数据库中结构是varchar类型，但是java代码查询的接口字段是long类型，查询字段类型不匹配，出现了隐式类型转换，所以索引失效走全表扫描。这个问题解决起来很容易，把java代码中的接口字段类型改成string就好了。
这个问题不容易发现，主要是表的问题，因为表都建好几年了，一开始数据量不大的时候没事，后面数据量慢慢变多，查询效率就下降的很明显了。优化之后，这条sql查询直接几十毫秒就返回了。

数据库分库分表做过吗？
考虑到改造成本和风险，就只把数据量比较大的记录表做过水平拆分。
具体操作就是数据库里建11张记录表，因为每一个操作记录都有一个申请单的id，因为这个申请单的id是自增的，所以后面插入数据的时候，就是根据申请单的id对11取模，根据取模结果决定插入哪张表，再去插入记录。然后查询记录数据的时候，也是先通过申请单的id对11取模，确定查询哪张表，再去通过申请单的id查询出关联的记录。
拆完后历史数据怎么迁移的？
这个主要通过定时任务做的数据迁移，每次从数据库查询50000条，然后通过偏移量依次往后推移，插入到新表中。
迁移的过程中有一批数据出现异常怎么办？
我们额外维护了一张异常表，有数据出现异常之后，会存入异常数据的初始id和结束id。先整体迁移一遍，最后再把异常表的数据迁移一遍，重试3次之后会邮件告警，人工定位。
迁移的过程中，客服有新的数据产生，是怎么处理的？
在迁移的过程中多估算一个结束下标，比如数据库有11万条数据，那我们会按照12万去做数据同步，这样后面产生的新数据也会被扫描到。
如果后续业务增长，11张记录表也不够用了怎么办？
这个后期业务增长也考虑到了，主要是针对申报表和记录表，分别维护了一张历史表。写一个定时任务，每一个月都会扫描申报表5年前的数据，把数据迁移到历史表中，原表数据进行物理删除，这样保证申报表的数据量始终维持在500~600万。一张申请单一般对应5~7条记录，所以记录表的数据量在2000~4000万左右，除以11张表，每张记录表平均的数据量在200~400万，也是比较合理的。
你们这个业务有没有用到时间段的范围查询，这种需求能兼容吗？
我们业务没有涉及时间段的范围查询，只是打开申报详情页，同时查询出所关联的记录。如果需要通过时间范围查询，可以使用分库分表中间件，比如mycat。
如果不使用中间件的话，可以通过维护一张路由表来实现时间段的范围查询。路由表只存申请单id和创建时间，时间段的范围查询先去路由表查询出申请单的id，再通过多线程去11张记录表拉取记录数据。
记录表干什么用的？
记录客服操作申请单的一些事件，比如领取、打回、补交材料等，让客服知道自己的历史操作。
引入redis分布式锁解决token过期导致大量请求打到第三方获取token接口报错问题。
详细讲一下这个问题？
有些政府的第三方，他们获取token的接口和传申报数据的接口是分开请求的，他们的token会不定期的更换。
首先，说一下这个token，第三方提供给我们一个获取token的接口，然后我们写了一个回调接口，把这个接口的域名和接口名给到第三方，他们会配置在后台，当我们去请求token的时候，他们不会直接返回token给我们，而是会把token异步传入我们提供的回调接口，然后，我们在该回调接口中对token做持久化和存入redis操作。
由于第三方会不定期的更换token，就可能导致很多用户在申报接口的时候，判断token过期了，然后会走请求token的流程，这样会有大量请求打到第三方的接口，触发他们的安全流控规则，导致大量用户创建申报单失败。
先说一下我对这个问题的分析：token过期后，不能让所有的请求都去更新token，这种并发问题就需要通过锁来解决，但是java的锁只能锁单台服务，我们部署了3台服务器，所以最终选择用redis的分布式锁来解决这个问题。
如果代码请求第三方的申报接口返回了504，说明出现了token过期。
在获取分布式锁之前，先查询redis中的token，对比当前token：如果不相等，说明token已经更新，直接使用redis中的token；如果相等，那就会加分布式锁，以固定字符串和当前token拼接作为锁的key。
锁里面的逻辑是还是先查询redis中的token，对比当前token：如果相等，说明token过期，会去调用获取token的接口，而第三方会将最新的token传入我们的回调函数，我们在回调函数中将token存入redis；如果不相等，说明token已经更新，则直接使用redis中的token。这样就实现了双重校验：确保只有一次请求去调用第三方获取token的接口，而其他请求则直接从redis中取出最新的token去调用第三方的申报接口。
这样就解决了由于token过期导致的并发请求问题，通过使用redis分布式锁和双重校验机制来减少对第三方接口的频繁调用。

对redission分布式锁的加锁原理了解吗？
了解，我可以从加锁机制，锁互斥性，可重入锁以及释放锁机制还有看门狗机制来谈一下这个问题。
首先加锁机制，其实加锁还是通过lua脚本实现的，因为能保证原子性，lua脚本首先会对是否存在key进行判断，如果不存在则进行加锁，加锁所使用的数据结构是hash结构，大key就是业务key，即需要我们设计的key，小key是uuid:线程id，第一次加锁value是1。
再说一下锁的互斥性，假如线程1已经加锁了，线程2来进行加锁也会执行同一个lua脚本，会先判断存在不存在这个key，发现已经存在（因为线程1和2的加锁key的一样的），如果存在其实还是通过hexists key线程id来判断hash结构中是否包含线程2的id，如果不包含，会返回线程1锁的剩余时间，然后通过while循环获取锁。
可重入的话跟互斥性判断逻辑是一样的，只是同一个线程进行判断都会成立，那么就会对通过incrby命令对hash结构中该key的value进行加1。
释放锁的原理就是调用lock.unlock()方法，会对这个持有锁的线程hash结构中的value进行减一，如果value是0的时候会用删除命令删除该锁。
Redission实现分布式锁比原生的setnxex主要多了一个功能，就是看门狗机制。他主要是防止任务没执行完，锁被提前释放了这种情况的发生。
其实就是一个后台定时任务线程，获取锁成功之后，会将持有锁的线程放入到一个映射表里面，然后每隔10秒检查一下，如果线程1是否还持有锁key（判断线程是否还持有key，其实就是遍历映射表里面线程id然后根据线程id去Redis中查，如果存在就会延长key的时间），如果存在，那么就会不断的延长锁key的生存时间。
如果服务宕机了，WatchDog机制线程也就没有了，此时就不会延长key的过期时间，到了30s之后就会自动过期了，其他线程就可以获取到锁。
如果调用带过期时间的lock方法，则不会启动看门狗任务去自动续期。
分布式锁key怎么设计的？
用的redission的lock锁，key是固定业务字符串加唯一token。
为什么这样设计？
并发性更好，这样就不是对所有token加锁，所以粒度应该精确到具体的申请单。
锁id和锁固定字符串有什么不一样？
锁的粒度不一样，锁token是针对这一个token加锁，锁固定字符串是对所有token加锁。
除了redis分布式锁还知道哪些可以加分布式锁？
数据库也可以实现分布式锁，创建一个带唯一约束的数据库表，用于存储锁的信息，例如锁的名称、过期时间等。当一个节点需要获取锁时，向数据库中插入一条记录，并将锁的名称、及过期时间填入相应字段。如果插入成功，则该节点获得了锁，可以执行相应的操作；否则，该节点等待一段时间后重试。当节点完成操作或者超过锁的过期时间时，释放锁，从数据库中删除相应的记录。
整合es重构申请单筛选功能，解决筛选条件多数据库索引瓶颈问题。
为什么要引入es？
其实技术选型有两种。第一种是选用数据库（把该表可以做垂直拆分，将热门搜索数据，单独维护一张表，然后一些占用字节多的且不经常查的字段数据，放在另一张表
），第二种就是选用es。
通过数据库对一些等值判断搜索，确实也能实现，但是无法解决以下3个问题：
1.我们这个业务有根据申请单名称模糊搜索，这样数据库始终有性能问题。
2.数据库索引有瓶颈问题，不能建立大量索引，如果有涉及根据申请单名称模糊查询，数据量大会很慢。
3.后期可能还会加新的筛选条件，这样在几百万的表加字段或者索引，会导致锁表很久。

怎么实现的？
难点主要涉及到es引入历史数据的清洗、插入数据、查询数据的业务需要变更。
基于es内存占用的考虑，我和我的导师商讨，不把所有的申报数据都存es，而是把用户搜索的关键数据存es，并且还存入申请单id，这样就可以先通过es查询出部分关键数据进行展示，如果用户要查看每一行数据后的详情页，就会走数据库主键索引查询详细数据。这样既节省了es的内存，又加快了查询的速度。
用户在页面上筛选的时候，有十几个索引，每个索引都只关联了一个申请单id。像图片表索引中，不会去保存图片的具体地址，只会保存一个状态，比如是否有图片；像办结表索引里，就保存办结状态信息（已完成或者未完成）。在数据库的申报表里走主键索引，只用花几毫秒就能查询上千万的数据，然后再依次查询图片表、办结表等信息进行封装返回，很快就能查询到我们需要的数据。
es集群是我导师搭建的，三主三从，每个节点3个分片3个副本。
我参与设计了索引的数据结构，并编写了数据的清洗代码、插入数据和查询数据代码。
es索引怎么设计的？
申请单名称text类型，因为需要分词
申请单状态byte类型
是否有图片byte类型
申请单类型integer
申请单工单id keyword
用户身份证号keyword
创建时间date
修改时间date
客服id long
申请单id long
es版本多少？
es7
为什么不把详情页所有数据都存es？
这个还是基于成本考虑，磁盘比内存便宜很多，走数据库主键索引也很快，所以做了一个拆分，es只做筛选。
用的什么什么分词器？
Ik分词器，主要会对申请单的名称进行分词。
清洗代码怎么写的？
我写了一个接口，先清洗历史数据，入参是开始的id和结束id，大概10万数据请求一次接口，因为我们数据库主键自增，就把1到10万条数据查出来，然后进行es所需要的数据格式进行组装，然后还需要根据这个申请单id查询图片表看看是否有图片，如果图片查询的集合不是空，则设置es对象这个属性为1，为空就为0，然后其他的数据也组装成es所需要的字段，插入es。
这个是历史数据的清洗，然后还需要改动的是插入申报信息的地方，申报信息入库后返回一个申请单主键id，这个id发消息到mq，然后消费方拿到这个id反查一次数据库，查到数据后进行es的数据组装，然后插入es，这里也用了重试3次的做法，就是如果es插入没有返回成功，会进行重试。
还需要改动的地方是页面通过筛选条件查询申报信息的地方，现在不是直接走数据库表查询了，是先通过es查询出部分数据，然后还有个详情页按钮，这个点击详情后再走数据库的主键索引，这个过程大大减少了查询时间，之前这些筛选条件可能都需要4秒左右响应，后面只需要0.几秒左右。
采用设计模式重构创建申请单接口并优化苏证通后台打开申请单详情页接口，将4秒优化到2秒左右完全展示。
问题出现：客服后期反馈打开用户申请单详情页的速度比较慢。
为什么之前没发现？
因为之前表数据量没这么多，后期表中数据量有700~800万条，开始打开变得缓慢，因为打开客服审批的界面，我们会把这个客服id下待处理的申请单的申请单数量，已办结的申请单数量，需要补齐补正的申请单数量，以及正在审核中的申请单数量以及详情页一些信息全部查出来，这些数据都在不同的表中。当时看了下查询了8张表并且还有涉及远程调用用户中心拉取用户详细信息数据，而且表的数据量都很大，并且都是串行拉取。
怎么定位的？
首先我要先复现问题，我通过公司的运维治理平台，用postman请求了一下打开审批页接口，发现耗时比较多的地方就是这几步查询的地方，一次查询在0.4到0.9秒左右，5次差不多2到4秒，这里因为都关联用户id，所以我就通过异步编排（CompletableFuture）的方式，改成了并发查询，将这些不同表的数据都通过多线程进行异步查询，然后进行数据组装返回。
此外，接口中能加缓存的地方也加了缓存，之前三级分类都是实时查询数据库，这块也改用了查redis缓存。

### 数据库和redis的缓存一致性怎么保证的？

我们使用的CacheAside模式，先写数据库，再写redis。
数据库插入数据之后，先删除redis中对应的key，然后再查询一次该key对应的数据库数据并插入到redis中。
从redis中取出数据，也是先从redis中取，如果查询不到，再去数据库中查询并放入redis中。

```java
public class UserService {
    @Autowired
    private RedisTemplate<String, User> redisTemplate;

    public User getUser(String id) {
        User user = redisTemplate.opsForValue().get("user:" + id);
        if (user == null) {
            user = loadFromDatabase(id);
            redisTemplate.opsForValue().set("user:" + id, user, 1, TimeUnit.HOURS);
        }
        return user;
    }

    public void updateUser(User user) {
        updateDatabase(user);
        redisTemplate.delete("user:" + user.getId());
    }
}
```

还知道其他缓存一致性方案吗？
1.缓存延时双删：先删除缓存，再更新数据库，休眠一会，再次删除缓存。
2.异步更新缓存：更新数据库后，发送更新缓存的消息到mq，消费者异步更新缓存。
设计模式怎么做的？
由于历史遗留问题，新增申请单都是采用新增接口的形式开发的，一个新的申请单对应一个新的接口，导致后期很多申请单接口游离在不同的类里，不方便统一维护，然后组长要求优化，就把这个需求交给了我。
我花了3天时间，把所有的申请单的接口都找到了，然后梳理出这些接口的公共逻辑和差异逻辑。发现这些申请单的差异逻辑主要有3个，分别是：
1.申请单的参数校验方法不同。不同的申请单参数校验的规则不一样；
2.组装参数的方法不一样。由于第三方提供的接口不一样，所以传给不同第三方需要的参数也不一样；
3.发送请求不一样。有些第三方的接口是httppost请求，有些是httpspost请求。
然后，这些申请单的公共逻辑主要就是数据入库和插入es，这些是每个申请单都有的业务，而且没有区别。所以，我最终决定使用模板方法模式、简单工厂模式以及策略模式，对新增申请单进行了重构，用一个接口实现。
首先，我创建了一个模板方法的抽象类AbstractApplyService，抽象方法是参数校验方法、参数组装方法和发送请求方法，公共方法是数据入库方法、插入es方法。
然后，把所有的申请单继承了这个抽象类，分别实现自己的抽象方法。并且，与前端约定了一组code，通过不同的数字代表不同的申请单，做了一个申请单类型枚举，申请单的code和其实现类的首字母小写做映射。
接着，我创建了一个申请单工厂，通过Spring的ApplicationContext自动注入抽象模板的所有实现类，返回一个map集合。这个map就是工厂，其中key是实现类的BeanName，value是具体的实现类对象。
最后，在工厂中定义了一个方法，根据传入的code，枚举映射对应的BeanName，通过map工厂匹配出具体的实现类返回。
这样优化之后，方便迭代，如果有新的申请单类型要开发，就只需要继承抽象类，实现不同的抽象方法，然后维护一个枚举就行了。
还知道哪些设计模式？
单例（双重检验锁、spring的单例bean）
责任链（spring中的过滤器）
动态代理（aop）
生产者消费者（队列）
观察者模式（监听器）
适配器模式（springmvc很多处理器适配器）
你们公司的线程池参数具体设置的值是多少？
核心线程数：20
最大线程数：80
过期时间：5分钟
时间单位：秒
工作队列：ArrayBlockingQueue
线程工厂：默认工厂
拒绝策略：CallerRunsPolicy-用调用者所在的线程来执行任务
为什么这样设置？
线程池的设置与3个指标有关系：单秒任务量、单个任务处理时间、时间单位。
举个例子，一般单秒任务量大的部门情况在0~200个，高峰期会到1000个，单个任务的处理时间是0.1秒，页面的最大响应时间是2秒。
一般核心线程数都以秒为单位来计算，所以1秒内要处理200个任务，那核心线程数就是200*0.1=20个。
20个核心线程1秒处理200个任务，最大响应时间是2秒，那就需要处理400个任务，那工作队列就需要放400-200=200个任务，工作队列的长度为200。
高峰期任务会有1000个，现在核心线程处理了200个，工作队列放了200个，还剩600个需要救急线程去处理，那救急线程数就是600*0.1=60个。
核心线程数20个，救急线程数60个，那最大线程数就是20+60=80个。
过期时间和任务的特点有关系。如果是定时任务这种，执行一次后要过很久再执行的，过期时间就可以设置的短一点，比如5~10秒，避免占用服务器资源；如果是接口类型这种，每时每刻都有请求过来的，过期时间就可以设置的长一点，比如5分钟，避免重复创建线程，增加服务器开销。
工作队列用默认的就行了。
线程工厂用默认的就行了。
拒绝策略一般根据任务的重要程度来选择。如果不能丢弃，用调用者所在的线程来执行任务。
接入sentinel并设置流控规则解决创建申报单接口qps过高导致某台服务器宕机问题。
问题：
之前我们上线的时候，没有考虑到一些热门的办件请求申报接口的qps超过了7000，单台机器qps3000多。因为部署了3台服务器，有一天下午服务器监控直接告警，有一台机器jvm参数采集失败，有一台服务宕机。我立马通过这个时间点去公司的运维监控平台，通过服务器的ip搜索了一下当时的请求量，发现已经达到了3500，直接宕机。
怎么解决的？
当时先是重启了服务，后面组长让我解决这个问题。我想到肯定要接入限流工具，然后对比了一下主流的限流工具，最后选用的是阿里的sentinel进行流控。
怎么接入的？
运维先帮我搭建好sentinel集群服务。
下面是我做的：
1.引入依赖spring-cloud-strter-alibaba-sentinel依赖
2.服务yml文件配置sentinel控制台地址
3.配置流控规则
4.代码中编写触发流控返回异常代码，编写降级代码
5.引入持久化，把sentinel流控配置持久化到nacos中
流控规则怎么配置的？
配置了2个规则。
第1个规则：qps单机阈值是2000，流控模式是关联模式，流控效果是快速失败，因为我们创建申报单接口直接影响公司的考核，所以该接口尽量不能受影响，用的关联模式，关联打开申报详情数据接口，当请求创建申报单接口qps过高于2000的时候是会让打开申报详情接口进行限流，降级逻辑给用户提示服务器繁忙请稍后重试。
第2个规则：当请求创建申请单接口qps高于3000的时候，流控模式是直接快速失败，因为高于3000服务器接口压力也承受不了。降级策略配置的慢调用比例，慢调用时间是1s，比例阈值是百分之50，熔断时常是5秒，最小请求数30000，统计时常是10s，降级逻辑给用户提示服务器繁忙请稍后重试。
定位过哪些线上问题？
测试反馈苏证通app线上运营的用户积分模块没展示。我查看了代码逻辑，发现该资源的从用户中心通过接口拉取并存入redis，会把每天不一样的任务类型下发给用户，因为用户中心有几千种任务，每天会根据他们那边的算法下发不一样的10种任务类型。
我首先想到可能是源头用户中心没有下发数据，通过postman测试用户中心该接口下发数据正常。后面觉得应该是我们这边的业务代码有问题，不过我后面看了一下这块的业务代码，发现也有3年没有变动过了，于是我就去线上查看线上服务器日志，发现一直在报错OOM。通过redis客户端命令info memory发现used_memory>=maxmemory,线上redis内存用的8g，云redis，查看配置文件内存溢出策略，发现设置的是禁止写入，运维让给出临时处理方案。准备把redis内存溢出策略改成删除很久不使用的key，重启redis，或者清空所有的key（风险很大），让程序重新初始化一次，运维不同意这样做，云redis，不是重大的问题不允许重启，可能会影响线上。
打开redis客户端，观察key，发现很多不同的key是以日期结尾，找到对应key的业务，发现问题，这里是一个定时任务，会以每天的日期和一个固定字符串做key拉取其他部门的数据然后存redis，而实际用户命中的redis数据也只是当天时间key有效，所以之前日期的key都没用，这样的key类型存在10几种，数量已经达到好几千个（历史遗留问题，随着时间推移迟早会溢出），然后用命令redis-cli --raw KEYS "key*" | xargs redis-cli DEL批量删除今天之前的该类业务key，redis内存瞬间由8g减少到2g，并且重新设置了redis内存溢出策略。在晚上9点后让运维重启了redis，重启是为了整理内存碎片问题，然后业务代码给当天的key加了24小时过期时间，问题后面就解决了。
为什么临时没有让运维扩容？
这个问题其实公司用的是云redis，运维当时说当时占的内存已经超过实际设置内存的2倍了，达到16g，说云redis有自动扩容的情况，像这种非正常情况占用的redis内存，不同意扩容，需要我们开发去定位问题。
怎么改的内存溢出策略?
临时解决是通过命令行redis-cli CONFIG SET maxmemory-policy allkeys-lru临时设置内存淘汰策略。最后修改配置文件maxmemory-policy配置项为allkeys-lru，等晚上用户量少的时候重启了redis。
在开发项目的时候，还有哪些常见的开发规范要遵循的？
1.编码规范，比如类名，方法名，变量名要用相同意思的英文单词，驼峰命名，代码中一些核心业务逻辑要加合适的注释。
2.在异常处理这块，尽量将捕获的异常粒度控制的细一点，不要任何异常都用exception代替，异常里面也要加合适的日志，方便后期追踪。
3.线程池方面，我们尽量用可配置参数线程池，这样能避免内存溢出。
4.代码中如果有equals比较，应该将不可能为空的字符串放在前面，这样能够避免空指针问题，使用hashmap的时候要进行数据判空，要设置初始容量大小。
Linux基本指令：
1.ls：列出所有文件及文件夹。
2.Pwd：找出当前所在的文件目录。
3.ps-ef|grep名称，找出这个应用进程。
4.rm-rf递归删除，
5.cp-rf递归复制。
6.Chmod：给文件改权限。
7.lsof-i:端口号查看端口是否被占用。
8.cat文件名|grep关键字，从文件中查找该关键字的记录。(查服务器日志需要)
9.tail-f文件名查看文件里面的内容，实时打印。(查服务器日志需要)
10.vi：编辑文件
11.setnu:给文件标识行数。(查服务器日志需要)
12.Linux创建文件的几种方式：touch文件名，vi和vim，echo。
